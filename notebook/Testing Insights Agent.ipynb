{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef136fdc-2415-45a9-ae90-a4ac7512ba51",
   "metadata": {
    "execution_time": {
     "end_time": "2026-01-18T06:24:14.118447Z",
     "start_time": "2026-01-18T06:24:12.533756Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from linkedin.langchain.chat_models.proxied_gpt_chat import ProxiedGPTChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "268240e7-a8f5-47f2-9fa0-1ecfbb2347e5",
   "metadata": {
    "execution_time": {
     "end_time": "2026-01-18T06:24:14.214776Z",
     "start_time": "2026-01-18T06:24:14.120018Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext linkedin.lisql\n",
    "%config SqlMagic.autocommit=False\n",
    "%manage_trino holdem\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab272068-24b8-426e-8f48-cce1e5dcf223",
   "metadata": {
    "execution_time": {
     "end_time": "2026-01-18T06:24:18.800998Z",
     "start_time": "2026-01-18T06:24:14.216720Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa077bd3-7135-4705-b11f-81f9601cedbc",
   "metadata": {
    "execution_time": {
     "end_time": "2026-01-18T06:24:18.881363Z",
     "start_time": "2026-01-18T06:24:18.802919Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Dict\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from linkedin.langchain.chat_models.proxied_gpt_chat import ProxiedGPTChat\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "#from langchain_community.stores.message.in_memory import InMemoryChatMessageHistory\n",
    "from IPython.display import Markdown, display\n",
    "from langchain.tools import tool\n",
    "from IPython import get_ipython\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8a2bd1-8b20-4d5c-8b8c-0bd900647046",
   "metadata": {},
   "source": [
    "```\n",
    "[User]\n",
    "   |\n",
    "   v\n",
    "[Query Handler / Orchestrator]\n",
    "   |\n",
    "   +--> Intent Detection\n",
    "   |\n",
    "   +--> Schema Fetcher (DESCRIBE table)\n",
    "   |\n",
    "   +--> SQL Generator (LLM)\n",
    "   |\n",
    "   +--> SQL Executor (Trino)\n",
    "   |\n",
    "   +--> Result Interpreter (LLM)\n",
    "   |\n",
    "   +--> Metrics Extractor\n",
    "   |\n",
    "   +--> Predictive Agent \n",
    "   |\n",
    "   +--> Memory System (SQLite)\n",
    "   |\n",
    "   v\n",
    "[Final Answer to User]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e045ac-094b-4d3a-9e5e-9eb11c663db6",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    %% =========================\n",
    "    %% USER + EXECUTION LAYER\n",
    "    %% =========================\n",
    "    subgraph L1[\"Execution Layer - Darwin Notebook\"]\n",
    "      U[\"User / Analyst\"] --> UI[\"Python Loop / CLI Input\\nwhile True: user_query\"]\n",
    "      UI --> ORCH[\"LangGraph Orchestrator\\n(StateGraph -> compiled.invoke)\"]\n",
    "    end\n",
    "\n",
    "    %% =========================\n",
    "    %% ORCHESTRATION + AGENTS\n",
    "    %% =========================\n",
    "    subgraph L2[\"Agent Layer - LangGraph Nodes\"]\n",
    "      ORCH --> ROUTER{\"Router / Intent Detector\\nneeds_sql? predictive?\"}\n",
    "\n",
    "      ROUTER -->|Follow-up or Memory| FOLLOW[\"Follow-up Resolver\\n(check recent_turns + metrics cache)\"]\n",
    "      ROUTER -->|Needs SQL| SQLGEN[\"SQL Generator Agent\\n(LLM -> SELECT + LIMIT)\"]\n",
    "      ROUTER -->|Recommendations| PRED[\"Predictive Reasoning Agent\\n(LLM -> next-test suggestions)\"]\n",
    "\n",
    "      FOLLOW --> QA[\"QA / Insights Agent\\n(LLM -> explanation + summary)\"]\n",
    "\n",
    "      SQLGEN --> SAFE{\"SQL Safety Gate\\nSELECT-only enforcement\"}\n",
    "      SAFE -->|Blocked| ERR[\"Error Response\\n(unsafe SQL or invalid query)\"]\n",
    "      SAFE -->|Allowed| EXEC[\"SQL Executor Tool Node\\nrun_trino_sql()\"]\n",
    "\n",
    "      EXEC --> METRICS[\"Metric Extraction Agent\\n(LLM -> JSON metrics)\"]\n",
    "      METRICS --> QA\n",
    "      QA --> OUT[\"Final Answer Returned\"]\n",
    "      ERR --> OUT\n",
    "      PRED --> OUT\n",
    "    end\n",
    "\n",
    "    %% =========================\n",
    "    %% MODEL LAYER\n",
    "    %% =========================\n",
    "    subgraph L3[\"Model Layer\"]\n",
    "      LLM[\"LinkedIn ProxiedGPTChat\\n(GPT-4.1 deployment)\"]\n",
    "    end\n",
    "\n",
    "    SQLGEN --> LLM\n",
    "    QA --> LLM\n",
    "    METRICS --> LLM\n",
    "    PRED --> LLM\n",
    "    FOLLOW --> LLM\n",
    "\n",
    "    %% =========================\n",
    "    %% DATA ACCESS LAYER\n",
    "    %% =========================\n",
    "    subgraph L4[\"Data Access Layer\"]\n",
    "      TRINO[\"Trino / Holdem\\n(%manage_trino holdem)\"]\n",
    "      DB[\"Analytics Tables\\n(u_mktgreporting.*)\"]\n",
    "      TRINO --> DB\n",
    "    end\n",
    "\n",
    "    EXEC --> TRINO\n",
    "\n",
    "    %% =========================\n",
    "    %% MEMORY LAYER\n",
    "    %% =========================\n",
    "    subgraph L5[\"Memory Layer\"]\n",
    "      STM[\"Short-Term Memory\\nIn-state: recent_turns last 3\\n+ older_summary\"]\n",
    "      LTM[\"Long-Term Memory\\nSQLite store keyword + recency\\nUser-scoped memories\"]\n",
    "      CKPT[\"LangGraph Checkpointer\\nSQLite checkpoints\"]\n",
    "    end\n",
    "\n",
    "    ROUTER <-->|reads| STM\n",
    "    FOLLOW <-->|reads| STM\n",
    "    QA <-->|reads| STM\n",
    "    PRED <-->|reads| STM\n",
    "\n",
    "    ROUTER <-->|retrieves notes| LTM\n",
    "    OUT -->|write compact QA| LTM\n",
    "    ORCH -->|persist state| CKPT\n",
    "    CKPT --> ORCH\n",
    "\n",
    "    %% =========================\n",
    "    %% OUTPUT\n",
    "    %% =========================\n",
    "    OUT --> UI --> U\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745dbba3-17ec-4570-91d1-4b4032430f38",
   "metadata": {
    "execution_time": {
     "end_time": "2026-01-18T06:29:44.996505Z",
     "start_time": "2026-01-18T06:28:43.648939Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reload_ext linkedin.lisql\n",
    "%config SqlMagic.autocommit=True\n",
    "%manage_trino holdem\n",
    "\n",
    "from typing import TypedDict, Dict, List, Optional, Tuple\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from linkedin.langchain.chat_models.proxied_gpt_chat import ProxiedGPTChat\n",
    "from langchain.tools import tool\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Markdown, display\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import sqlite3\n",
    "import base64\n",
    "import hashlib\n",
    "\n",
    "# -----------------------------\n",
    "# 1) SQL Tool (rollback + retry)\n",
    "# -----------------------------\n",
    "@tool\n",
    "def run_trino_sql(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Execute a SQL query via Darwin %sql magic.\n",
    "    Auto-ROLLBACK + retry once if Trino transaction gets stuck.\n",
    "    \"\"\"\n",
    "    ip = get_ipython()\n",
    "    try:\n",
    "        result = ip.run_line_magic(\"sql\", query)\n",
    "        try:\n",
    "            pdf = result.DataFrame()\n",
    "            return pdf.head(200).to_markdown(index=False)\n",
    "        except Exception:\n",
    "            return str(result)\n",
    "    except Exception as e:\n",
    "        err = str(e)\n",
    "        if \"invalid transaction\" in err.lower() or \"rolled back\" in err.lower():\n",
    "            try:\n",
    "                ip.run_line_magic(\"sql\", \"ROLLBACK\")\n",
    "                result = ip.run_line_magic(\"sql\", query)\n",
    "                try:\n",
    "                    pdf = result.DataFrame()\n",
    "                    return pdf.head(200).to_markdown(index=False)\n",
    "                except Exception:\n",
    "                    return str(result)\n",
    "            except Exception as e2:\n",
    "                return f\"SQL_ERROR: {str(e2)}\"\n",
    "        return f\"SQL_ERROR: {err}\"\n",
    "\n",
    "# -----------------------------\n",
    "# 2) LLM\n",
    "# -----------------------------\n",
    "chat = ProxiedGPTChat(\n",
    "    resource_id=\"yourorg-resource-id\",\n",
    "    deployment_id=\"yourorg-deployment-id\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=2500\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Prompts\n",
    "# -----------------------------\n",
    "SQL_GEN_SYSTEM_PROMPT = \"\"\"\n",
    "You are a LinkedIn Trino SQL expert.\n",
    "\n",
    "Rules:\n",
    "- ONLY write SELECT statements.\n",
    "- You will be given the exact table schema (columns). Use only those columns.\n",
    "- If the user asks for \"insights\" or \"show me this table\", return:\n",
    "  SELECT * FROM <table> LIMIT 50\n",
    "- Always include LIMIT <= 200 unless aggregation is requested.\n",
    "Return ONLY SQL.\n",
    "\"\"\"\n",
    "\n",
    "QA_SYSTEM_PROMPT = \"\"\"\n",
    "You are a LinkedIn analytics explanation expert.\n",
    "Explain results clearly, highlight patterns and useful takeaways.\n",
    "If the SQL errored, explain why and what to do next.\n",
    "\"\"\"\n",
    "\n",
    "METRIC_EXTRACTION_PROMPT = \"\"\"\n",
    "Extract key numeric values from the SQL results and return JSON only.\n",
    "Example: {\"total_rows\": 50, \"pct_change\": -15.2}\n",
    "\"\"\"\n",
    "\n",
    "PREDICTIVE_SYSTEM_PROMPT = \"\"\"\n",
    "You are a senior experimentation strategist.\n",
    "Use metrics + results context to recommend next tests, guardrails, or next actions.\n",
    "Stay practical and grounded in the observed table output.\n",
    "\"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Long-term memory (SQLite keyword + recency)\n",
    "# -----------------------------\n",
    "def _pbkdf2_hash_password(password: str, salt: bytes, rounds: int = 200_000) -> bytes:\n",
    "    return hashlib.pbkdf2_hmac(\"sha256\", password.encode(\"utf-8\"), salt, rounds)\n",
    "\n",
    "def _tokenize(text: str) -> List[str]:\n",
    "    text = (text or \"\").lower()\n",
    "    return re.findall(r\"[a-z0-9_]+\", text)\n",
    "\n",
    "def _keyword_score(query: str, doc: str) -> float:\n",
    "    q_toks = set(_tokenize(query))\n",
    "    d_toks = set(_tokenize(doc))\n",
    "    if not q_toks:\n",
    "        return 0.0\n",
    "    overlap = len(q_toks.intersection(d_toks))\n",
    "    return overlap / max(len(q_toks), 1)\n",
    "\n",
    "class LongTermMemorySQLite:\n",
    "    def __init__(self, db_path: str):\n",
    "        self.db_path = db_path\n",
    "        self._init_db()\n",
    "\n",
    "    def _conn(self):\n",
    "        return sqlite3.connect(self.db_path)\n",
    "\n",
    "    def _init_db(self):\n",
    "        with self._conn() as con:\n",
    "            cur = con.cursor()\n",
    "            cur.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS users (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    username TEXT UNIQUE NOT NULL,\n",
    "                    salt_b64 TEXT NOT NULL,\n",
    "                    pw_hash_b64 TEXT NOT NULL,\n",
    "                    created_ts REAL NOT NULL\n",
    "                )\n",
    "            \"\"\")\n",
    "            cur.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS memories (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    user_id INTEGER NOT NULL,\n",
    "                    created_ts REAL NOT NULL,\n",
    "                    text TEXT NOT NULL,\n",
    "                    FOREIGN KEY(user_id) REFERENCES users(id)\n",
    "                )\n",
    "            \"\"\")\n",
    "            cur.execute(\"CREATE INDEX IF NOT EXISTS idx_memories_user_ts ON memories(user_id, created_ts)\")\n",
    "            con.commit()\n",
    "\n",
    "    def create_user(self, username: str, password: str) -> int:\n",
    "        salt = os.urandom(16)\n",
    "        pw_hash = _pbkdf2_hash_password(password, salt)\n",
    "        with self._conn() as con:\n",
    "            cur = con.cursor()\n",
    "            cur.execute(\n",
    "                \"INSERT INTO users(username, salt_b64, pw_hash_b64, created_ts) VALUES (?, ?, ?, ?)\",\n",
    "                (username, base64.b64encode(salt).decode(), base64.b64encode(pw_hash).decode(), time.time())\n",
    "            )\n",
    "            con.commit()\n",
    "            return int(cur.lastrowid)\n",
    "\n",
    "    def authenticate(self, username: str, password: str) -> Optional[int]:\n",
    "        with self._conn() as con:\n",
    "            cur = con.cursor()\n",
    "            cur.execute(\"SELECT id, salt_b64, pw_hash_b64 FROM users WHERE username=?\", (username,))\n",
    "            row = cur.fetchone()\n",
    "            if not row:\n",
    "                return None\n",
    "            uid, salt_b64, pw_hash_b64 = row\n",
    "            salt = base64.b64decode(salt_b64)\n",
    "            expected = base64.b64decode(pw_hash_b64)\n",
    "            got = _pbkdf2_hash_password(password, salt)\n",
    "            return int(uid) if got == expected else None\n",
    "\n",
    "    def create_or_auth(self, username: str, password: str) -> int:\n",
    "        uid = self.authenticate(username, password)\n",
    "        return uid if uid is not None else self.create_user(username, password)\n",
    "\n",
    "    def add_memory(self, user_id: int, text: str):\n",
    "        if not text.strip():\n",
    "            return\n",
    "        with self._conn() as con:\n",
    "            cur = con.cursor()\n",
    "            cur.execute(\"INSERT INTO memories(user_id, created_ts, text) VALUES (?, ?, ?)\", (user_id, time.time(), text))\n",
    "            con.commit()\n",
    "\n",
    "    def search(self, user_id: int, query: str, k: int = 5, candidate_limit: int = 300) -> List[str]:\n",
    "        with self._conn() as con:\n",
    "            cur = con.cursor()\n",
    "            cur.execute(\"SELECT created_ts, text FROM memories WHERE user_id=? ORDER BY created_ts DESC LIMIT ?\",\n",
    "                        (user_id, candidate_limit))\n",
    "            rows = cur.fetchall()\n",
    "\n",
    "        now = time.time()\n",
    "        scored = []\n",
    "        for ts, text in rows:\n",
    "            s = _keyword_score(query, text)\n",
    "            age_days = max((now - float(ts)) / 86400, 0.0)\n",
    "            recency = 0.08 * (1.0 / (1.0 + age_days / 30.0))\n",
    "            scored.append((s + recency, text))\n",
    "        scored.sort(reverse=True, key=lambda x: x[0])\n",
    "        return [t for _, t in scored[:k]]\n",
    "\n",
    "lt_store = LongTermMemorySQLite(\"long_term_memory_noembed.sqlite\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Helpers\n",
    "# -----------------------------\n",
    "def is_predictive_question(q: str) -> bool:\n",
    "    triggers = [\"suggest\", \"recommend\", \"next test\", \"predict\", \"improve\", \"strategy\", \"what should we do next\"]\n",
    "    return any(t in (q or \"\").lower() for t in triggers)\n",
    "\n",
    "def extract_table_name(user_q: str) -> Optional[str]:\n",
    "    m = re.search(r\"([a-zA-Z0-9_]+\\.[a-zA-Z0-9_]+)\", user_q or \"\")\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "# -----------------------------\n",
    "# 6) State\n",
    "# -----------------------------\n",
    "class AppState(TypedDict, total=False):\n",
    "    user_id: int\n",
    "    user_query: str\n",
    "    memory: Dict[str, object]\n",
    "    metrics: Dict[str, float]\n",
    "    answer: str\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Predictive Agent\n",
    "# -----------------------------\n",
    "def run_predictive_agent(state: AppState) -> AppState:\n",
    "    user_id = state.get(\"user_id\")\n",
    "    user_q = state.get(\"user_query\", \"\")\n",
    "    memory = state.get(\"memory\", {\"older_summary\": \"\", \"recent_turns\": []})\n",
    "    metrics = state.get(\"metrics\", {})\n",
    "\n",
    "    lt_hits = lt_store.search(user_id, user_q) if user_id is not None else []\n",
    "\n",
    "    prompt = [\n",
    "        SystemMessage(content=PREDICTIVE_SYSTEM_PROMPT),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "Long-term memories:\n",
    "{lt_hits}\n",
    "\n",
    "Short summary:\n",
    "{memory.get('older_summary','')}\n",
    "\n",
    "Recent turns:\n",
    "{memory.get('recent_turns',[])}\n",
    "\n",
    "Metrics:\n",
    "{metrics}\n",
    "\n",
    "User question:\n",
    "{user_q}\n",
    "        \"\"\")\n",
    "    ]\n",
    "    resp = chat.invoke(prompt).content.strip()\n",
    "\n",
    "    memory[\"recent_turns\"].append({\"role\": \"user\", \"content\": user_q})\n",
    "    memory[\"recent_turns\"].append({\"role\": \"assistant\", \"content\": resp})\n",
    "    memory[\"recent_turns\"] = memory[\"recent_turns\"][-6:]\n",
    "\n",
    "    if user_id is not None:\n",
    "        lt_store.add_memory(user_id, f\"Q: {user_q}\\nA: {resp}\")\n",
    "\n",
    "    return {\"answer\": resp, \"memory\": memory, \"metrics\": metrics}\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Main Handler (FIXED: schema-aware SQL generation)\n",
    "# -----------------------------\n",
    "def handle_query(state: AppState) -> AppState:\n",
    "    user_id = state.get(\"user_id\")\n",
    "    user_q = state.get(\"user_query\", \"\")\n",
    "    memory = state.get(\"memory\") or {\"older_summary\": \"\", \"recent_turns\": []}\n",
    "    metrics = state.get(\"metrics\") or {}\n",
    "\n",
    "    if is_predictive_question(user_q):\n",
    "        return run_predictive_agent(state)\n",
    "\n",
    "    table = extract_table_name(user_q)\n",
    "\n",
    "    # Pull long-term context\n",
    "    lt_hits = lt_store.search(user_id, user_q) if user_id is not None else []\n",
    "\n",
    "    context_text = \"\"\n",
    "    if lt_hits:\n",
    "        context_text += \"Long-term context:\\n\" + \"\\n\".join(f\"- {x}\" for x in lt_hits) + \"\\n\\n\"\n",
    "    if memory.get(\"older_summary\"):\n",
    "        context_text += f\"Short history summary:\\n{memory['older_summary']}\\n\\n\"\n",
    "\n",
    "    # If table exists, fetch schema first (this is the key fix)\n",
    "    schema_md = \"\"\n",
    "    if table:\n",
    "        schema_md = run_trino_sql(f\"DESCRIBE {table}\")\n",
    "\n",
    "    needs_sql = True  # always execute SQL if table is provided\n",
    "\n",
    "    if needs_sql and table:\n",
    "        sql_msgs = [\n",
    "            SystemMessage(content=SQL_GEN_SYSTEM_PROMPT),\n",
    "            HumanMessage(content=f\"\"\"\n",
    "{context_text}\n",
    "\n",
    "User question:\n",
    "{user_q}\n",
    "\n",
    "Target table:\n",
    "{table}\n",
    "\n",
    "Table schema:\n",
    "{schema_md}\n",
    "            \"\"\")\n",
    "        ]\n",
    "        sql_query = chat.invoke(sql_msgs).content.strip()\n",
    "\n",
    "        sql_results = run_trino_sql(sql_query) if sql_query.strip().upper().startswith(\"SELECT\") else f\"SQL_ERROR: Unsafe SQL: {sql_query}\"\n",
    "\n",
    "        metric_msgs = [\n",
    "            SystemMessage(content=METRIC_EXTRACTION_PROMPT),\n",
    "            HumanMessage(content=f\"SQL Results:\\n{sql_results}\")\n",
    "        ]\n",
    "        metric_resp = chat.invoke(metric_msgs).content.strip()\n",
    "        try:\n",
    "            parsed = json.loads(metric_resp)\n",
    "            for k, v in parsed.items():\n",
    "                try:\n",
    "                    metrics[k] = float(v)\n",
    "                except:\n",
    "                    pass\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        interpret_msgs = [\n",
    "            SystemMessage(content=QA_SYSTEM_PROMPT),\n",
    "            HumanMessage(content=f\"\"\"\n",
    "{context_text}\n",
    "\n",
    "User question:\n",
    "{user_q}\n",
    "\n",
    "SQL query:\n",
    "{sql_query}\n",
    "\n",
    "SQL results:\n",
    "{sql_results}\n",
    "\n",
    "Extracted metrics:\n",
    "{metrics}\n",
    "            \"\"\")\n",
    "        ]\n",
    "        final_answer = chat.invoke(interpret_msgs).content.strip()\n",
    "    else:\n",
    "        final_answer = chat.invoke([\n",
    "            SystemMessage(content=QA_SYSTEM_PROMPT),\n",
    "            HumanMessage(content=f\"{context_text}\\nUser question: {user_q}\")\n",
    "        ]).content.strip()\n",
    "\n",
    "    # Update short-term memory\n",
    "    memory[\"recent_turns\"].append({\"role\": \"user\", \"content\": user_q})\n",
    "    memory[\"recent_turns\"].append({\"role\": \"assistant\", \"content\": final_answer})\n",
    "    memory[\"recent_turns\"] = memory[\"recent_turns\"][-6:]\n",
    "\n",
    "    if user_id is not None:\n",
    "        lt_store.add_memory(user_id, f\"Q: {user_q}\\nA: {final_answer}\")\n",
    "\n",
    "    return {\"answer\": final_answer, \"memory\": memory, \"metrics\": metrics}\n",
    "\n",
    "# -----------------------------\n",
    "# 9) Build graph\n",
    "# -----------------------------\n",
    "graph = StateGraph(AppState)\n",
    "graph.add_node(\"handle_query\", handle_query)\n",
    "graph.add_edge(START, \"handle_query\")\n",
    "graph.add_edge(\"handle_query\", END)\n",
    "compiled = graph.compile()\n",
    "\n",
    "# -----------------------------\n",
    "# 10) Interactive loop\n",
    "# -----------------------------\n",
    "USER = \"demo_user\"\n",
    "PASS = \"demo_pass_123\"\n",
    "user_id = lt_store.create_or_auth(USER, PASS)\n",
    "\n",
    "state = {\"memory\": {\"older_summary\": \"\", \"recent_turns\": []}, \"metrics\": {}}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\nAsk your query (exit/quit/bye/q to end): \").strip()\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"bye\", \"q\"]:\n",
    "        print(\"\\nSession ended.\\n\" + \"=\" * 60)\n",
    "        break\n",
    "\n",
    "    out = compiled.invoke({\n",
    "        \"user_id\": user_id,\n",
    "        \"user_query\": user_input,\n",
    "        \"memory\": state[\"memory\"],\n",
    "        \"metrics\": state[\"metrics\"]\n",
    "    })\n",
    "\n",
    "    state[\"memory\"] = out.get(\"memory\", state[\"memory\"])\n",
    "    state[\"metrics\"] = out.get(\"metrics\", state[\"metrics\"])\n",
    "    display(Markdown(out[\"answer\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1671de9a-1a7e-4560-890f-9726402f31b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "darwin": {
   "resource_id": 15369340,
   "username": "mbhavana"
  },
  "kernelspec": {
   "display_name": "Python3-Scratchpad",
   "language": "python",
   "name": "python3-scratchpad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
